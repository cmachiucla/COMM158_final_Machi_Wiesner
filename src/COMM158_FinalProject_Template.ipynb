{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "### Dataset Description ###\n",
        "###########################\n",
        "# This dataset contains Twitter posts from the time of the Donald Trump vs. Hillary Clinton election.\n",
        "# Tweets related to each candidate are stored in separate CSV files.\n",
        "# Each CSV file includes the following information:\n",
        "## Timestamp (created_at) – The date and time when the tweet was posted.\n",
        "## Likes (favorite_count) – The number of likes the tweet received.\n",
        "## Retweets (retweet_count) – The number of times the tweet was shared.\n",
        "## Content (text) – The text of the tweet.\n"
      ],
      "metadata": {
        "id": "w4MRrwYlx8sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "### Part 1: Guided Data Exploration   ###\n",
        "#########################################\n",
        "\n",
        "# 1.1 Merging CSV Files\n",
        "# Load the two CSV files from the data folder into a single Pandas DataFrame.\n",
        "# Make sure to add a new column to keep track of the candidate name associated with each tweet.\n"
      ],
      "metadata": {
        "id": "cWQzFq3YNozA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Sentiment Analysis\n",
        "# We will use the NRC Emotion Lexicon, a lexicon that categorizes words based on emotions and sentiment.\n",
        "\n",
        "# About the NRC Emotion Lexicon:\n",
        "# Download the NRC Emotion Lexicon from: https://github.com/aditeyabaral/lok-sabha-election-twitter-analysis/blob/master/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\n",
        "# This lexicon provides 10 sentiments:\n",
        "## Eight emotions: Anger, anticipation, disgust, fear, joy, sadness, surprise, and trust.\n",
        "## Two valences: Positive and negative.\n",
        "# The file has three columns: word, emotion, and association (binary: 1 = associated, 0 = not associated).\n",
        "\n",
        "# This is an example code for loading the lexicon into your Python file.\n",
        "# Here, we filter out unnecessary rows (association == 0), so that we only keep the rows necessary for emotion analysis.\n",
        "# Feel free to directly use it, or edit it in ways you'd like!\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nrc_lexicon = pd.read_csv(\"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\", sep=\"\\t\", header=None, names=[\"word\", \"emotion\", \"association\"])\n",
        "nrc_lexicon = nrc_lexicon[nrc_lexicon[\"association\"] == 1].drop(columns=[\"association\"])\n",
        "print(nrc_lexicon.head())\n"
      ],
      "metadata": {
        "id": "i-OcMW9lrmZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2.1 Create a Sentiment Analysis Function:\n",
        "## The input of the function should be the text of one tweet.\n",
        "## The output should be a count of each of the 10 sentiment categories."
      ],
      "metadata": {
        "id": "7w2BDmCpecjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2.2 Apply the self-defined function to the text column of the merged data frame from #1.1.\n",
        "## The output should be the original merged DataFrame with 10 additional columns,\n",
        "## one for each sentiment, containing the count of that sentiment in the tweet."
      ],
      "metadata": {
        "id": "44-NClGOPAxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Hierarchical Indexing & Summary Statistics\n",
        "# 1.3.1 Group by candidate and generate summary statistics (describe()) for each emotion category.\n",
        "# 1.3.2 Group by candidate and each emotion category, then compute summary statistics for favorite and retweets."
      ],
      "metadata": {
        "id": "lPreSuwLLg9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4 Visualizing Results\n",
        "# Create one graph with 2 sub figures (i.e. 1 row 2 columns).\n",
        "# For both figures, emotion categories should be the x-axis, and candidate names as the legend.\n",
        "# The first subplot should have likes (favorite_count) as y-axis, and the second subplot should have retweets (retweet_count) as y-axis."
      ],
      "metadata": {
        "id": "esw05KYCL1po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################\n",
        "### Part 2: Correlation Analysis ###\n",
        "####################################\n",
        "\n",
        "# 2.1 Research Question: Is there a relationship between emotion categories and the number of retweets or favorites?\n",
        "# Conduct correlation analysis between emotion counts and likes/retweets.\n",
        "# To report your results, include a plot and a paragraph.\n",
        "# For the paragraph writeup, feel free to write them as comments next to your code or plot."
      ],
      "metadata": {
        "id": "BsGLuQjoF7ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "### Part 3: Open Ended Explorations ###\n",
        "#######################################\n",
        "\n",
        "# Explore this dataset: What interesting patterns and insights do you see? What notable trends or relationships can you identify?\n",
        "# Focus on formulating and testing hypotheses, rather than confirming or disproving them.\n",
        "\n",
        "# Notes on grading criteria:\n",
        "## Whether a hypothesis is confirmed or not is not the focus.\n",
        "## Rather, ensure that your hypothesis is well-formed and that your code can legitimately test it.\n",
        "## Results should be accurate—whether they are surprising or not does not impact grading.\n",
        "\n",
        "# Since this is a group project with 2 or 3 members, the final report should contain 2 or 3 sets of explorations depending on the group size.\n",
        "# Each member should be responsible for 1 set of exploration.\n",
        "# Each set of exploration should contain:\n",
        "## A brief summary paragraph of your exploration (research question, analysis method used, interpretation of results/plots)\n",
        "## The code you write for this exploration\n",
        "## Visualizing the results (at least 1 plot)\n",
        "\n",
        "# For example, one big question you can ask is that:\n",
        "# Can this Twitter dataset provide any indication that predicts the outcome of the election?\n",
        "\n",
        "# To emphasize the importance of collaboration:\n",
        "# At least two of exploration sets must build upon one another.\n",
        "# This could mean extending previous findings, refining an analysis method, adding deeper insight to an initial result, etc.\n",
        "# In your submission, include a few sentences explaining how analyses build upon one another.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z4_ou9hk5Zn1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}