# -*- coding: utf-8 -*-
"""COMM158_FinalProject_Template.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oMjxcSTB2S4qDKQEx5YqzzY2za3dlOnn
"""

###########################
### Dataset Description ###
###########################
# This dataset contains Twitter posts from the time of the Donald Trump vs. Hillary Clinton election.
# Tweets related to each candidate are stored in separate CSV files.
# Each CSV file includes the following information:
## Timestamp (created_at) – The date and time when the tweet was posted.
## Likes (favorite_count) – The number of likes the tweet received.
## Retweets (retweet_count) – The number of times the tweet was shared.
## Content (text) – The text of the tweet.

#########################################
### Part 1: Guided Data Exploration   ###
#########################################

# 1.1 Merging CSV Files
# Load the two CSV files from the data folder into a single Pandas DataFrame.
# Make sure to add a new column to keep track of the candidate name associated with each tweet.

"Hello World"
print("Hello World")

# 1.2 Sentiment Analysis
# We will use the NRC Emotion Lexicon, a lexicon that categorizes words based on emotions and sentiment.

# About the NRC Emotion Lexicon:
# Download the NRC Emotion Lexicon from: https://github.com/aditeyabaral/lok-sabha-election-twitter-analysis/blob/master/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt
# This lexicon provides 10 sentiments:
## Eight emotions: Anger, anticipation, disgust, fear, joy, sadness, surprise, and trust.
## Two valences: Positive and negative.
# The file has three columns: word, emotion, and association (binary: 1 = associated, 0 = not associated).

# This is an example code for loading the lexicon into your Python file.
# Here, we filter out unnecessary rows (association == 0), so that we only keep the rows necessary for emotion analysis.
# Feel free to directly use it, or edit it in ways you'd like!

import nltk
from nltk.tokenize import word_tokenize

nrc_lexicon = pd.read_csv("NRC-Emotion-Lexicon-Wordlevel-v0.92.txt", sep="\t", header=None, names=["word", "emotion", "association"])
nrc_lexicon = nrc_lexicon[nrc_lexicon["association"] == 1].drop(columns=["association"])
print(nrc_lexicon.head())

# 1.2.1 Create a Sentiment Analysis Function:
## The input of the function should be the text of one tweet.
## The output should be a count of each of the 10 sentiment categories.

# 1.2.2 Apply the self-defined function to the text column of the merged data frame from #1.1.
## The output should be the original merged DataFrame with 10 additional columns,
## one for each sentiment, containing the count of that sentiment in the tweet.

# 1.3 Hierarchical Indexing & Summary Statistics
# 1.3.1 Group by candidate and generate summary statistics (describe()) for each emotion category.
# 1.3.2 Group by candidate and each emotion category, then compute summary statistics for favorite and retweets.

# 1.4 Visualizing Results
# Create one graph with 2 sub figures (i.e. 1 row 2 columns).
# For both figures, emotion categories should be the x-axis, and candidate names as the legend.
# The first subplot should have likes (favorite_count) as y-axis, and the second subplot should have retweets (retweet_count) as y-axis.

####################################
### Part 2: Correlation Analysis ###
####################################

# 2.1 Research Question: Is there a relationship between emotion categories and the number of retweets or favorites?
# Conduct correlation analysis between emotion counts and likes/retweets.
# To report your results, include a plot and a paragraph.
# For the paragraph writeup, feel free to write them as comments next to your code or plot.

#######################################
### Part 3: Open Ended Explorations ###
#######################################

# Explore this dataset: What interesting patterns and insights do you see? What notable trends or relationships can you identify?
# Focus on formulating and testing hypotheses, rather than confirming or disproving them.

# Notes on grading criteria:
## Whether a hypothesis is confirmed or not is not the focus.
## Rather, ensure that your hypothesis is well-formed and that your code can legitimately test it.
## Results should be accurate—whether they are surprising or not does not impact grading.

# Since this is a group project with 2 or 3 members, the final report should contain 2 or 3 sets of explorations depending on the group size.
# Each member should be responsible for 1 set of exploration.
# Each set of exploration should contain:
## A brief summary paragraph of your exploration (research question, analysis method used, interpretation of results/plots)
## The code you write for this exploration
## Visualizing the results (at least 1 plot)

# For example, one big question you can ask is that:
# Can this Twitter dataset provide any indication that predicts the outcome of the election?

# To emphasize the importance of collaboration:
# At least two of exploration sets must build upon one another.
# This could mean extending previous findings, refining an analysis method, adding deeper insight to an initial result, etc.
# In your submission, include a few sentences explaining how analyses build upon one another.
